{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "root = src.parent\n",
    "sys.path.append(str(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? False\n",
      "Number of GPUs 0\n"
     ]
    }
   ],
   "source": [
    "#initialize GPU -  In case of windows use cuda instead of nps\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "print(\"Number of GPUs\",torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simple RNN \n",
    "Use the RNN model to predict the temporal evolution of flooding.\\\n",
    "The input time span is 10 simulation timesteps, and the output is 1 simulation timestep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Networks import SimpleRNN\n",
    "from utils.simulation import Simulation\n",
    "from train import train_and_validate, evaluate_model\n",
    "# from train import train_and_validate, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(series,T=10,H=1):\n",
    "    # This function creates a dataset of input/output sequences from a time series.\n",
    "    # The input sequence is T steps long, from time t to time t+T (excluded).\n",
    "    # The output sequence is H steps long, from time t+T to time t+T+H (excluded).\n",
    "    # Codes here represents that two type of dataset will be generated, the first one\n",
    "    # (input time sequence) means that the dataset used for training, and the second one\n",
    "    # (output time sequence) means that the dataset used for prediction, amd hence it is\n",
    "    # distributed from span t+T to t+T+H\n",
    "    X = []\n",
    "    Y = []\n",
    "    for t in range(len(series)-T-H):\n",
    "        x = series[t:t+T]\n",
    "        X.append(x)\n",
    "        y = series[t+T:t+T+H]\n",
    "        Y.append(y)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 64, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(86, 10, 64, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(86, 1, 64, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sims = Simulation.load_simulations(str(root)+\"/data/processed_data/normalized_training_data\", sim_amount = 1, number_grids=64)\n",
    "display(sims[0].wd.shape)\n",
    "\n",
    "seqX, seqY = create_sequences(sims[0].wd, T =10, H =1)\n",
    "display(seqX.shape)\n",
    "display(seqY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tra.shape: (60, 10, 64, 64), Y_tra.shape: (60, 1, 64, 64)\n",
      "X_val.shape: (13, 10, 64, 64), Y_val.shape: (13, 1, 64, 64)\n",
      "X_tst.shape: (13, 10, 64, 64), Y_tst.shape: (13, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# We keep track of indexes of train and validation.\n",
    "seqX_tra, seqX_tst, seqY_tra, seqY_tst, iseqx_tra, iseqx_tst = train_test_split(\n",
    "    seqX, seqY, np.arange(seqX.shape[0]), test_size=0.30, shuffle=True, random_state=42)\n",
    "\n",
    "# Split the existing test dataset into validation and test sets (50/50 split)\n",
    "seqX_val, seqX_tst, seqY_val, seqY_tst, iseqx_val, iseqx_tst = train_test_split(\n",
    "    seqX_tst, seqY_tst, iseqx_tst, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"X_tra.shape: {seqX_tra.shape}, Y_tra.shape: {seqY_tra.shape}\")\n",
    "print(f\"X_val.shape: {seqX_val.shape}, Y_val.shape: {seqY_val.shape}\")\n",
    "print(f\"X_tst.shape: {seqX_tst.shape}, Y_tst.shape: {seqY_tst.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path):\n",
    "    best_val_loss = float(\"inf\")  # Track the best validation loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    start_time = time.time()  # Start training time\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation Phase\n",
    "        avg_val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Save Best Model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}', f'Train Loss: {avg_train_loss:.4f}, '\n",
    "                  f'Validation Loss: {avg_val_loss:.4f}', f'Best Validation Loss: {best_val_loss:.4f}')\n",
    "    train_time = time.time() - start_time\n",
    "    print(\"Training complete.\")\n",
    "    return train_losses, val_losses, best_val_loss, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "RNN: Expected input to be 2-D or 3-D but received 5-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/trained_models/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m train_losses, val_losses, best_val_loss, time_RNN \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(save_path))\n",
      "Cell \u001b[1;32mIn[62], line 15\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\sagi8\\anaconda3\\envs\\dsaie\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\DS-AI\\src\\models\\Networks.py:17\u001b[0m, in \u001b[0;36mSimpleRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)   \u001b[38;5;66;03m# Assuming input x has shape (batch, sequence)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# RNN layer\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m x, hn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# We do not need the hidden states hn\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Select the output of the last time step\u001b[39;00m\n\u001b[0;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\sagi8\\anaconda3\\envs\\dsaie\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sagi8\\anaconda3\\envs\\dsaie\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:476\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    475\u001b[0m     batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN: Expected input to be 2-D or 3-D but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    478\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: RNN: Expected input to be 2-D or 3-D but received 5-D tensor"
     ]
    }
   ],
   "source": [
    "model_name = 'CNN-RNN'\n",
    "\n",
    "batch_size=4\n",
    "num_epochs = 200\n",
    "lr = 0.0005\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW\n",
    "model = SimpleRNN(10,1).to(device)\n",
    "\n",
    "#create datasets and data loaders\n",
    "train_dataset = TensorDataset(torch.tensor(seqX_tra, dtype=torch.float32), torch.tensor(seqY_tra, dtype=torch.float32))\n",
    "val_dataset = TensorDataset(torch.tensor(seqX_val, dtype=torch.float32), torch.tensor(seqY_val, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# defining the optimizer\n",
    "optimizer = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "# defining the save path\n",
    "save_path = \"../results/trained_models/\" + model_name\n",
    "\n",
    "# training\n",
    "train_losses, val_losses, best_val_loss, time_RNN = train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rnn(model = SimpleRNN,\n",
    "          sim_amount=1,\n",
    "          training_size=0.8,\n",
    "          batch_size=4,\n",
    "          num_epochs = 200,\n",
    "          lr = 0.0005,\n",
    "          criterion = nn.MSELoss(),\n",
    "          optimizer = optim.AdamW,\n",
    "          model_name = 'babies_first_RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_length = 10 # number of simulation\n",
    "grid_size = 64 # number of grid\n",
    "timestep = 96 # number of time step\n",
    "\n",
    "# Create a sample 2D array\n",
    "input_data = torch.rand((sequence_length, input_size))\n",
    "\n",
    "# Reshape into a 3D tensor (simulation_length, timestep, grid_size)\n",
    "input_data = input_data.unsqueeze(1).expand(-1, batch_size, -1)\n",
    "\n",
    "# Create an RNN layer\n",
    "rnn = nn.RNN(input_size, hidden_size=10, num_layers=1, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading(sim_amount):\n",
    "    sims = Simulation.load_simulations(str(root)+\"/data/processed_data/normalized_training_data\", sim_amount = sim_amount, number_grids=64)\n",
    "\n",
    "    n_timesteps = 96\n",
    "    grid_size = 64\n",
    "    channels = 2   # water depth and topography\n",
    "\n",
    "    # reformat the data\n",
    "    X = np.zeros((n_timesteps*len(sims), grid_size, grid_size, channels))   # timestep * grid_x * grid_y * channels\n",
    "    Y = np.zeros(X[:,:,:,0].shape)   # timestep * grid_x * grid_y\n",
    "\n",
    "    for i in range(len(sims)):   # number of simulations loaded in for training/validation\n",
    "\n",
    "        sim = sims[i]            # get simulation\n",
    "        topography = sim.topography\n",
    "\n",
    "        for t_i in range(n_timesteps):    # number of timesteps\n",
    "\n",
    "            wd, vx, vy = sim.return_timestep(t_i)\n",
    "            X[t_i+i*n_timesteps, :, :, 0] = wd\n",
    "            X[t_i+i*n_timesteps, :, :, 1] = topography\n",
    "\n",
    "            wd, vx, vy = sim.return_timestep(t_i+1)\n",
    "            Y[t_i+i*n_timesteps, :, :] = wd\n",
    "\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = loading(sim_amount = 1)\n",
    "display(X.shape) # input (DEM, WD) - one simulation\n",
    "display(Y.shape) # output (WD) - one simulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
