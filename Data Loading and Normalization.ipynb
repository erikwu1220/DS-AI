{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "from urllib.request import urlretrieve\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Imported because Roberto also did it.\n",
    "# from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dem, waterdepth, x_velocity, y_velocity data\n",
    "path = \"data/raw_datasets/\" \n",
    "\n",
    "allfiles_dem = glob.glob(path + 'DEM/*.txt')\n",
    "allfiles_wd = glob.glob(path + 'WD/*.txt')\n",
    "allfiles_vx = glob.glob(path + 'VX/*.txt')\n",
    "allfiles_vy = glob.glob(path + 'VY/*.txt')\n",
    "\n",
    "dem = []\n",
    "wd = []\n",
    "vx = []\n",
    "vy = []\n",
    "\n",
    "for i in range(len(allfiles_dem)):\n",
    "    dem.append(np.loadtxt(allfiles_dem[i]))\n",
    "    wd.append(np.loadtxt(allfiles_wd[i]))\n",
    "    vx.append(np.loadtxt(allfiles_vx[i]))\n",
    "    vy.append(np.loadtxt(allfiles_vy[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of grids (in one axis)\n",
    "number_grids = 64\n",
    "\n",
    "# Simulation index (range:0-136)\n",
    "sim = 0\n",
    "sim_len = len(wd)\n",
    "\n",
    "# Timestep index (range:0-96)\n",
    "t = 0\n",
    "t_len = len(wd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract DEM data at specific simulation\n",
    "dem_sim = np.reshape(dem[sim][:,2],(number_grids,number_grids))\n",
    "# Extract the water depth, vx, and vy value at specific time\n",
    "wd_sim = np.reshape(wd[sim][t],(number_grids,number_grids))\n",
    "vx_sim = np.reshape(vx[sim][t],(number_grids,number_grids))\n",
    "vy_sim = np.reshape(vy[sim][t],(number_grids,number_grids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking all the simulation for normalization \n",
    "# Note that each of the simulation contains t = 0 - 96\n",
    "wd_allArray = wd[0]\n",
    "vx_allArray = vx[0]\n",
    "vy_allArray = vy[0]\n",
    "\n",
    "for x in range(1,len(wd)):\n",
    "    wd_allArray = np.concatenate((wd_allArray, wd[i]),axis=0)\n",
    "    vx_allArray = np.concatenate((vx_allArray, vx[i]),axis=0)\n",
    "    vy_allArray = np.concatenate((vy_allArray, vy[i]),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_pyg(graph, pos, DEM, WD, VX, VY):\n",
    "#     '''\n",
    "#     Converts a graph or mesh into a PyTorch Geometric Data type \n",
    "#     Then, add position, DEM, and water variables to data object.\n",
    "#     Adapted from https://github.com/RBTV1/SWE-GNN-paper-repository-/blob/main/database/graph_creation.py\n",
    "#     '''\n",
    "#     DEM = DEM.reshape(-1)\n",
    "\n",
    "#     edge_index = torch.LongTensor(list(graph.edges)).t().contiguous()\n",
    "#     row, col = edge_index\n",
    "\n",
    "#     data = Data()\n",
    "\n",
    "#     delta_DEM = torch.FloatTensor(DEM[col]-DEM[row])\n",
    "#     coords = torch.FloatTensor(get_coords(pos))\n",
    "#     edge_relative_distance = coords[col] - coords[row]\n",
    "#     edge_distance = torch.norm(edge_relative_distance, dim=1)\n",
    "#     edge_slope = delta_DEM/edge_distance\n",
    "\n",
    "#     data.edge_index = edge_index\n",
    "#     data.edge_distance = edge_distance\n",
    "#     data.edge_slope = edge_slope\n",
    "#     data.edge_relative_distance = edge_relative_distance\n",
    "\n",
    "#     data.num_nodes = graph.number_of_nodes()\n",
    "#     data.pos = torch.tensor(list(pos.values()))\n",
    "#     data.DEM = torch.FloatTensor(DEM)\n",
    "#     data.WD = torch.FloatTensor(WD.T)\n",
    "#     data.VX = torch.FloatTensor(VX.T)\n",
    "#     data.VY = torch.FloatTensor(VY.T)\n",
    "        \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here use the Min-max normalization to normalize the water depth over the entire simulation sequence (0-130)\n",
    "def scale_sequences(X,scaler=None,scaler_type='minmax'):\n",
    "    \"\"\"\n",
    "    Uses a minmax scaler to transform sequences. The scaler is created if no scaler is passed as argument.\n",
    "    Adapted from exercise notebook on drinking water demand.\n",
    "    \n",
    "    The input parameter X is a two-dimensional array.\n",
    "    \"\"\"\n",
    "    \n",
    "    Xshape=X.shape\n",
    "    if scaler:\n",
    "        X = scaler.transform(X.reshape(-1,1)).reshape(Xshape)\n",
    "        return X\n",
    "    else:\n",
    "        if scaler_type == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaler_type == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise Exception(\"Type of scikit-learn scaler not supported. Choose 'standard' or 'minmax.\")\n",
    "        X = scaler.fit_transform(X.reshape(-1,1)).reshape(Xshape)\n",
    "        return X, scaler\n",
    "    \n",
    "def denormalize(image_tensor, mean, std):\n",
    "    # Denormalize the image\n",
    "    denorm_img = image_tensor * std[:, None, None] + mean[:, None, None]\n",
    "    # Clip values to be between 0 and 1\n",
    "    denorm_img = denorm_img.clip(0, 1)\n",
    "    return denorm_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of waterdepth and velocity\n",
    "wd_scale, scaler = scale_sequences(wd_allArray ,scaler=None,scaler_type='minmax')\n",
    "vx_scale, scaler = scale_sequences(vx_allArray ,scaler=None,scaler_type='minmax')\n",
    "vy_scale, scaler = scale_sequences(vy_allArray ,scaler=None,scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After normalization all the data, split them into the original form (131 simulations with t = 0-96 of each)\n",
    "wd_norm = np.vsplit(wd_scale,sim_len)\n",
    "vx_norm = np.vsplit(vx_scale,sim_len)\n",
    "vy_norm = np.vsplit(vy_scale,sim_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the train and testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vx_tra): 91\n",
      "len(vx_val): 20\n",
      "len(vx_tst): 20\n"
     ]
    }
   ],
   "source": [
    "# First, Split the dataset into following portion: training(70%), testing(15%), validation(15%)\n",
    "# Second, Split the existing test dataset into validation and test sets (50/50 split)\n",
    "\n",
    "# Water depth\n",
    "wd_tra, wd_tst, iwd_tra, iwd_tst = train_test_split(\n",
    "    wd_norm, np.arange(sim_len), test_size=0.30, shuffle=True, random_state=42)\n",
    "\n",
    "wd_val, wd_tst, iwd_val, iwd_tst = train_test_split(\n",
    "    wd_tst, iwd_tst, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# X velocity\n",
    "vx_tra, vx_tst, ivx_tra, ivx_tst = train_test_split(\n",
    "    vx_norm, np.arange(sim_len), test_size=0.30, shuffle=True, random_state=42)\n",
    "\n",
    "vx_val, vx_tst, ivx_val, ivx_tst = train_test_split(\n",
    "    vx_tst, ivx_tst, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Y velocity\n",
    "vy_tra, vy_tst, ivy_tra, ivy_tst = train_test_split(\n",
    "    vy_norm, np.arange(sim_len), test_size=0.30, shuffle=True, random_state=42)\n",
    "\n",
    "vy_val, vy_tst, ivy_val, ivy_tst = train_test_split(\n",
    "    vy_tst, ivy_tst, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"len(vx_tra): {len(vy_tra)}\")\n",
    "print(f\"len(vx_val): {len(vy_val)}\")\n",
    "print(f\"len(vx_tst): {len(vy_tst)}\")\n",
    "\n",
    "# Note that the form of the training dataset is a list containing multiple arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagi8\\AppData\\Local\\Temp\\ipykernel_23716\\1896039322.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_abjetg6_iu\\croot\\pytorch_1686932924616\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  train_dataset = TensorDataset(torch.tensor(wd_tra, dtype=torch.float32), torch.tensor(Y_tra, dtype=torch.float32))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_tra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mtensor(wd_tra, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mY_tra\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mtensor(wd_val, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(Y_val, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mtensor(wd_tst, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(Y_tst, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32 ))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_tra' is not defined"
     ]
    }
   ],
   "source": [
    "# Not finished yet!!!\n",
    "\n",
    "\n",
    "# train_dataset = TensorDataset(torch.tensor(wd_tra, dtype=torch.float32), torch.tensor(Y_tra, dtype=torch.float32))\n",
    "# val_dataset = TensorDataset(torch.tensor(wd_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32))\n",
    "# test_dataset = TensorDataset(torch.tensor(wd_tst, dtype=torch.float32), torch.tensor(Y_tst, dtype=torch.float32 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
