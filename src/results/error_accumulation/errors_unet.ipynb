{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as calc_mse\n",
    "\n",
    "# Local\n",
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent.parent\n",
    "root = src.parent\n",
    "sys.path.append(str(src))\n",
    "\n",
    "from models.mlp import MLP\n",
    "from models.unet import UNet\n",
    "from models.unet_source import UNet_source\n",
    "from models.unet_mask import UNet_mask\n",
    "\n",
    "from utils.watertopo import WaterTopo\n",
    "from utils.utils import recursive_pred, mse_per_timestep, get_corner\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "Load the simulations of test 1, create inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (20, 1, 2, 64, 64)\n",
      "Y0:  (20, 97, 1, 64, 64)\n",
      "Y5:  (20, 17, 1, 64, 64)\n",
      "Y10:  (20, 9, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "grid_size = 64\n",
    "channels = 2\n",
    "\n",
    "sims = WaterTopo.load_simulations(str(root)+\"/data/normalized_data/test1\", sim_amount=20, number_grids=grid_size, use_augmented_data=True)\n",
    "\n",
    "dur = len(sims[0].wd)\n",
    "\n",
    "X   = np.zeros((len(sims), 1, 2, grid_size, grid_size))\n",
    "Y0  = np.zeros((len(sims), dur, 1, grid_size, grid_size))\n",
    "Y5  = Y0[:,::5+1,:,:,:]\n",
    "Y10 = Y0[:,::10+1,:,:,:]\n",
    "\n",
    "for i,sim in enumerate(sims):\n",
    "    X[i,:,0,:,:] = sim.topography\n",
    "    X[i,:,1,:,:] = sim.wd[0]\n",
    "\n",
    "    Y0[i,:,0,:,:]  = sim.wd\n",
    "    Y5[i,:,0,:,:]  = sim.implement_skips(5).wd\n",
    "    Y10[i,:,0,:,:] = sim.implement_skips(10).wd\n",
    "\n",
    "print(\"X: \", X.shape)\n",
    "print(\"Y0: \", Y0.shape)\n",
    "print(\"Y5: \", Y5.shape)\n",
    "print(\"Y10: \", Y10.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multistep-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = UNet(2, [32, 64, 128], 96)\n",
    "model_type = \"unet_multistep\"\n",
    "model_name = \"unet_32_64_128_orig_data80_multistep_skip0\"\n",
    "Y = Y0\n",
    "skips = 0\n",
    "\n",
    "model.load_state_dict(torch.load(str(src)+\"/results/trained_models/\" + model_type + \"/\" + model_name, \n",
    "                                 map_location=\"cpu\"))\n",
    "\n",
    "mse = np.zeros((len(sims), Y.shape[1]))\n",
    "\n",
    "for i, sim in enumerate(sims):\n",
    "    inputs = torch.tensor(X[i], dtype=torch.float32)\n",
    "    outputs = model(inputs).squeeze()\n",
    "\n",
    "    outputs = torch.cat((torch.tensor(sim.wd[0], dtype=torch.float32).unsqueeze(0), outputs), dim=0)\n",
    "    \n",
    "    mse[i,:] = mse_per_timestep(Y[i].squeeze(), outputs)\n",
    "\n",
    "mse = np.mean(mse, axis=0)\n",
    "t = np.arange(0, 97, skips+1)\n",
    "mse = np.vstack([t, mse])\n",
    "\n",
    "# np.savetxt(str(src)+\"/results/error_accumulation/\"+model_name, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-regressive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.10000000e+01 2.20000000e+01 3.30000000e+01\n",
      "  4.40000000e+01 5.50000000e+01 6.60000000e+01 7.70000000e+01\n",
      "  8.80000000e+01]\n",
      " [5.42474701e-24 2.20505564e-02 2.97099462e-02 3.81496206e-02\n",
      "  4.63352532e-02 5.36467716e-02 5.97951938e-02 6.42383775e-02\n",
      "  6.72610081e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = UNet_source(2, 1)\n",
    "model_type = \"unet\"\n",
    "model_name = \"unet_source_aug_skip5\"\n",
    "Y = Y10\n",
    "skips = 10\n",
    "\n",
    "model.load_state_dict(torch.load(str(src)+\"/results/trained_models/\" + model_type + \"/\" + model_name, \n",
    "                                 map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "mse = np.zeros((len(sims), Y.shape[1]))\n",
    "\n",
    "for i, sim in enumerate(sims):\n",
    "    inputs = torch.tensor(X[i], dtype=torch.float32).squeeze()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = recursive_pred(model, inputs, Y.shape[1]-1, include_first_timestep=True)\n",
    "    \n",
    "    mse[i,:] = mse_per_timestep(Y[i].squeeze(), outputs)\n",
    "\n",
    "mse = np.mean(mse, axis=0)\n",
    "t = np.arange(0, 97, skips+1)\n",
    "mse = np.vstack([t, mse])\n",
    "\n",
    "# np.savetxt(str(src)+\"/results/error_accumulation/\"+model_name, mse)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 6.00000000e+00 1.20000000e+01 1.80000000e+01\n",
      "  2.40000000e+01 3.00000000e+01 3.60000000e+01 4.20000000e+01\n",
      "  4.80000000e+01 5.40000000e+01 6.00000000e+01 6.60000000e+01\n",
      "  7.20000000e+01 7.80000000e+01 8.40000000e+01 9.00000000e+01\n",
      "  9.60000000e+01]\n",
      " [5.42474701e-24 1.56773795e-03 3.43045790e-03 6.09518038e-03\n",
      "  9.66525755e-03 1.39607415e-02 1.84215745e-02 2.27112738e-02\n",
      "  2.65715951e-02 3.03082432e-02 3.36909858e-02 3.62233176e-02\n",
      "  3.81002499e-02 3.93075290e-02 3.98939746e-02 4.01820495e-02\n",
      "  4.03193243e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = UNet_mask(2, [32, 64], 1, 5)\n",
    "model_type = \"unet_mask\"\n",
    "model_name = \"unet_32_64_orig_data80_skip5_hardmask5\"\n",
    "Y = Y5\n",
    "skips = 5\n",
    "\n",
    "model.load_state_dict(torch.load(str(src)+\"/results/trained_models/\" + model_type + \"/\" + model_name, \n",
    "                                 map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "mse = np.zeros((len(sims), Y.shape[1]))\n",
    "\n",
    "for i, sim in enumerate(sims):\n",
    "    inputs = torch.tensor(X[i], dtype=torch.float32).squeeze()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = recursive_pred(model, inputs, Y.shape[1]-1, include_first_timestep=True)\n",
    "    \n",
    "    mse[i,:] = mse_per_timestep(Y[i].squeeze(), outputs)\n",
    "\n",
    "mse = np.mean(mse, axis=0)\n",
    "t = np.arange(0, 97, skips+1)\n",
    "mse = np.vstack([t, mse])\n",
    "\n",
    "# np.savetxt(str(src)+\"/results/error_accumulation/\"+model_name, mse)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01768131961300556\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = MLP(2, 256, 1)\n",
    "model_type = \"mlp\"\n",
    "model_name = \"mlp_corners_aug_data\"\n",
    "\n",
    "model.load_state_dict(torch.load(str(src)+\"/results/trained_models/\" + model_type + \"/\" + model_name, \n",
    "                                 map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "for i, sim in enumerate(sims):\n",
    "    inputs = np.zeros((grid_size, grid_size, channels))\n",
    "    targets = np.zeros((grid_size, grid_size))\n",
    "\n",
    "    inputs[:,:,0] = get_corner(sim.wd[0])\n",
    "    inputs[:,:,1] = sim.topography\n",
    "    targets[:,:,] = sim.return_timestep(-1)\n",
    "\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    mse = calc_mse(targets, outputs.squeeze())\n",
    "\n",
    "np.savetxt(str(src)+\"/results/error_accumulation/\"+model_name, np.array([0,mse]))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
