{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "root = src.parent\n",
    "sys.path.append(str(src))\n",
    "sys.path.append(str(root))\n",
    "\n",
    "from utils.watertopo import WaterTopo\n",
    "from utils.simulation import Simulation\n",
    "from utils.utils import count_parameters, mse_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNN_3D import CNN_3D, create_sequence, train_and_validate, evaluate_model, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? False\n",
      "Number of GPUs 0\n"
     ]
    }
   ],
   "source": [
    "#initialize GPU -  In case of windows use cuda instead of nps\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "print(\"Number of GPUs\",torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN --> num. trainable parameters:  338881\n"
     ]
    }
   ],
   "source": [
    "model = CNN_3D(  input_channels=3,\n",
    "                 hidden_size=64,\n",
    "                 output_channels=1,\n",
    "                 bias=True,\n",
    "                 kernel_size=(3, 3, 3, 3), \n",
    "                 pool_kernel_size=1,\n",
    "                 pool_stride=1, \n",
    "                 nonlinearity=F.relu\n",
    "                 ).to(device)\n",
    "\n",
    "print(f\"CNN --> num. trainable parameters:{count_parameters(model):8d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (93, 3, 2, 64, 64)\n",
      "shape of Y:  (93, 1, 1, 64, 64)\n",
      "starting training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m----> 6\u001b[0m     model, train_losses, val_losses, best_val_loss, time \u001b[38;5;241m=\u001b[39m train(model,\n\u001b[1;32m      7\u001b[0m                                                       device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m      8\u001b[0m                                                       root\u001b[38;5;241m=\u001b[39mroot,\n\u001b[1;32m      9\u001b[0m                                                       model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN/SpatCNN\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                                       channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                                       T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                                       H\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                                       sim_amount\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     14\u001b[0m                                                       training_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m     15\u001b[0m                                                       use_augmented_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m                                                       batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                                       num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                                       lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m,\n\u001b[1;32m     19\u001b[0m                                                       criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[1;32m     20\u001b[0m                                                       optimizer\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW,\n\u001b[1;32m     21\u001b[0m                                                       )\n",
      "File \u001b[0;32m~/DASAIE/FLOODS_project/floods/src/models/CNN_3D.py:206\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, root, model_name, channels, T, H, sim_amount, training_size, use_augmented_data, batch_size, num_epochs, lr, criterion, optimizer)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m train_losses, val_losses, best_val_loss, time \u001b[38;5;241m=\u001b[39m train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[1;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(save_path))\n",
      "File \u001b[0;32m~/DASAIE/FLOODS_project/floods/src/models/CNN_3D.py:106\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\u001b[0m\n\u001b[1;32m    104\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    105\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 106\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    107\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m    108\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/DASAIE/FLOODS_project/floods/src/models/CNN_3D.py:66\u001b[0m, in \u001b[0;36mCNN_3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))))\n\u001b[1;32m     65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n\u001b[0;32m---> 66\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x))))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#print(\"after 4 convolution: \", x.size())\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    595\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    596\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    607\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Uncomment to train the model, otherwise load the best parameters below\n",
    "training = True\n",
    "\n",
    "if training:\n",
    "\n",
    "    model, train_losses, val_losses, best_val_loss, time = train(model,\n",
    "                                                      device=device,\n",
    "                                                      root=root,\n",
    "                                                      model_name = 'CNN/SpatCNN',\n",
    "                                                      channels=2,\n",
    "                                                      T=3,\n",
    "                                                      H=1,\n",
    "                                                      sim_amount=1,\n",
    "                                                      training_size=0.8,\n",
    "                                                      use_augmented_data=False,\n",
    "                                                      batch_size=10,\n",
    "                                                      num_epochs=20,\n",
    "                                                      lr=0.005,\n",
    "                                                      criterion=nn.MSELoss(),\n",
    "                                                      optimizer=optim.AdamW,\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot validation loss\n",
    "# fig, ax = plt.subplots(figsize=(20, 5))\n",
    "# ax.plot(train_losses, label='Training Loss')\n",
    "# ax.plot(val_losses, label='Validation Loss')\n",
    "# ax.set_xlabel('Epochs')\n",
    "# ax.set_ylabel('Loss')\n",
    "# ax.set_title('Training and validation losses - CNN')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(inputs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     34\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targets, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 35\u001b[0m targets[\u001b[38;5;241m0\u001b[39m,:, :,:] \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,:,:]\n\u001b[1;32m     37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(targets\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     38\u001b[0m outputs[\u001b[38;5;241m0\u001b[39m,:, :,:] \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,:,:]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": [
    "# This cell saves the averaged MSE for each timestep for 20 test simulations\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(str(src)+\"/results/trained_models/cnn/SpatCNN\"))\n",
    "\n",
    "grid_size = 64\n",
    "channels = 2\n",
    "sim_length = 97\n",
    "timesteps = 3\n",
    "\n",
    "# Let's do a crude Monte Carlo with a single model, calculating the loss after each timestep\n",
    "sims = WaterTopo.load_simulations(str(root)+\"/data/normalized_data/test1/\", 20, grid_size, use_augmented_data=True)\n",
    "mse = np.zeros(97)\n",
    "\n",
    "for sim in sims:\n",
    "\n",
    "   inputs = np.zeros((1, timesteps, channels, grid_size, grid_size))\n",
    "   targets = sim.wd\n",
    "\n",
    "\n",
    "   # Select the time step where you want to start\n",
    "   id = 0\n",
    "\n",
    "   inputs[0, :, 0, :, :] = sim.topography\n",
    "   inputs[0, 0, :, :, :] = sim.return_timestep(id)\n",
    "   inputs[0, 1, :,  :, :] = sim.return_timestep(id)\n",
    "   inputs[0, 2, :, :, :] = sim.return_timestep(id)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "\n",
    "   targets = torch.tensor(targets, dtype=torch.float32)\n",
    "   targets[0,:, :,:] = inputs[0,1,:,:]\n",
    "\n",
    "   outputs = torch.zeros(targets.shape)\n",
    "   outputs[0,:, :,:] = inputs[0,1,:,:]\n",
    "\n",
    "   for t in range(1, sim_length):\n",
    "      outputs[t,:,:] = model(inputs.to(device)).detach()\n",
    "      inputs[0,1,:,:] = outputs[t,:,:]\n",
    "\n",
    "   mse += mse_per_timestep(targets, outputs)\n",
    "\n",
    "mse = mse / len(sims)\n",
    "\n",
    "np.savetxt(str(src)+\"/results/error_accumulation/CNN\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 5D input (got 4D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(inputs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m inputs\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m---> 37\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Plotting inputs (time series)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m axs[i]\u001b[38;5;241m.\u001b[39mimshow(targets[\u001b[38;5;241m0\u001b[39m,:,:])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/DASAIE/FLOODS_project/floods/src/models/CNN_3D.py:63\u001b[0m, in \u001b[0;36mCNN_3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Convolutions\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m#print(\"input: \", x.size())\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))))\n\u001b[1;32m     64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))))\n\u001b[1;32m     65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:138\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_dim(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:525\u001b[0m, in \u001b[0;36mBatchNorm3d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 5D input (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected 5D input (got 4D input)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try the model!\n",
    "model.eval()\n",
    "\n",
    "grid_size = 64\n",
    "channels = 2\n",
    "\n",
    "f,axs = plt.subplots(2, 4, figsize=(20,10))\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "for i in range(0, len(axs), 2):\n",
    "  with torch.no_grad():\n",
    "      # Randomly select a simulation\n",
    "      random_index = random.randint(0, 80)\n",
    "      sim = WaterTopo.load_simulations(str(root)+\"/data/normalized_data/tra_val/\", \n",
    "                                       1, \n",
    "                                       grid_size)[0]\n",
    "\n",
    "      inputs = np.zeros((3, channels, grid_size, grid_size))\n",
    "      targets = np.zeros((1, grid_size, grid_size))\n",
    "\n",
    "      id = random.randint(0, 95)\n",
    "\n",
    "     \n",
    "      inputs[0, 0, :, :] = sim.topography\n",
    "      inputs[0, 1, :, :] = sim.return_timestep(id)\n",
    "      inputs[1, 0, :, :] = sim.topography\n",
    "      inputs[1, 1, :, :] = sim.return_timestep(id)\n",
    "      inputs[2, 0, :, :] = sim.topography\n",
    "      inputs[2, 1, :, :] = sim.return_timestep(id)\n",
    "    \n",
    "    \n",
    "      targets[0, :,:]  = sim.return_timestep(id+1)\n",
    "\n",
    "      # Predict\n",
    "      inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n",
    "      inputs.cpu()\n",
    "      prediction = model(inputs).cpu()\n",
    "\n",
    "      # Plotting inputs (time series)\n",
    "      axs[i].imshow(targets[0,:,:])\n",
    "      axs[i+1].imshow(prediction[0,0,:,:])\n",
    "\n",
    "      axs[i].set_title(f\"Target: (test) simulation {random_index}\")\n",
    "      axs[i+1].set_title(f\"Prediction: (test) simulation {random_index}\")\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
