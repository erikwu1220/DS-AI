{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path().resolve()\n",
    "src = cwd.parent\n",
    "root = src.parent\n",
    "sys.path.append(str(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? True\n",
      "Number of GPUs 1\n"
     ]
    }
   ],
   "source": [
    "#initialize GPU -  In case of windows use cuda instead of nps\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "print(\"Number of GPUs\",torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each of the simulations used for training and validation has a total of 96 timesteps, with a spatial grid size of 64*64=4096.\n",
    "- Data has already been normalized.\n",
    "- Each of the training/validation simulations therefore gives 96 pairs of inputs and targets.\n",
    "- Each input contains at minimum 4096 values (if only water depth is used) and at most 4096 * 4 = 16384 (if water depth, vx, vy, and topography are used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.RNN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRNN\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleRNN\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleRNN(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models.RNN'"
     ]
    }
   ],
   "source": [
    "from models.RNN import SimpleRNN\n",
    "\n",
    "model = SimpleRNN(*args, **kwargs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from utils.simulation import Simulation\n",
    "from train import train_and_validate, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(model,\n",
    "              sim_amount=1,\n",
    "              training_size=0.8,\n",
    "              batch_size=4,\n",
    "              num_epochs = 200,\n",
    "              lr = 0.0005,\n",
    "              criterion = nn.MSELoss(),\n",
    "              optimizer = optim.AdamW,\n",
    "              model_name = 'babie_first_RNN'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This method trains a simple RNN. Given a single timestep consisting of water depth and topography (both 64*64), the RNN predicts a single step ahead. The best model state is\n",
    "    saved following the save_path, and also returned by the method.\n",
    "    \n",
    "    Description of arguments:\n",
    "    - model: the model to be trained, should be an instance of the class SimpleRNN;\n",
    "    - sim_amount (int): number of simulations of which the data is loaded and used for training, with a maximum of 400;\n",
    "    - training_size (float): fraction of data to use for training (validation uses the fraction 1 - training_size);\n",
    "    - batch_size (int): batch size used during training (you can modify this based on your requirements);\n",
    "    - num_epochs (int): number of epochs used during training;\n",
    "    - lr (float): learning rate used during training;\n",
    "    - criterion: Loss function, default nn.MSELoss()\n",
    "    - optimizer: optimizer used for training, default optim.AdamW\n",
    "    - model_name (string): the best model state will be saved in ../results/trained_models/ under this name\n",
    "\n",
    "    returns: model, train_losses, val_losses, best_val_loss, time\n",
    "    \"\"\"\n",
    "    # load simulations to be used for training\n",
    "    sims = Simulation.load_simulations(str(root)+\"/data/processed_data/normalized_training_data\", sim_amount=sim_amount, number_grids=64)\n",
    "\n",
    "    n_timesteps = 96\n",
    "    grid_size = 64\n",
    "    channels = 2   # water depth and topography\n",
    "\n",
    "    # reformat the data\n",
    "    X = np.zeros((n_timesteps*len(sims), grid_size, grid_size, channels))   # timestep * grid_x * grid_y * channels\n",
    "    Y = np.zeros(X[:,:,:,0].shape)   # timestep * grid_x * grid_y\n",
    "\n",
    "    for i in range(len(sims)):   # number of simulations loaded in for training/validation\n",
    "\n",
    "        sim = sims[i]            # get simulation\n",
    "        topography = sim.topography\n",
    "\n",
    "        for t_i in range(n_timesteps):    # number of timesteps\n",
    "\n",
    "            wd, vx, vy = sim.return_timestep(t_i)\n",
    "            X[t_i+i*n_timesteps, :, :, 0] = wd\n",
    "            X[t_i+i*n_timesteps, :, :, 1] = topography\n",
    "\n",
    "            wd, vx, vy = sim.return_timestep(t_i+1)\n",
    "            Y[t_i+i*n_timesteps, :, :] = wd\n",
    "\n",
    "    # split the data into training and validation\n",
    "    id_training = int(training_size * len(X))\n",
    "\n",
    "    X_tra = X[:id_training, :]\n",
    "    Y_tra = Y[:id_training, :]\n",
    "\n",
    "    X_val = X[id_training:, :]\n",
    "    Y_val = Y[id_training:, :]\n",
    "\n",
    "    print(\"X_tra.shape: \", X_tra.shape)\n",
    "    print(\"Y_tra.shape: \", Y_tra.shape)\n",
    "    print(\"X_val.shape: \", X_val.shape)\n",
    "    print(\"Y_val.shape: \", Y_val.shape)\n",
    "\n",
    "    #create datasets and data loaders\n",
    "    train_dataset = TensorDataset(torch.tensor(X_tra, dtype=torch.float32), torch.tensor(Y_tra, dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # defining the optimizer\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "    # defining the save path\n",
    "    save_path = \"../results/trained_models/\" + model_name\n",
    "\n",
    "    # training\n",
    "    train_losses, val_losses, best_val_loss, time = train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    return model, train_losses, val_losses, best_val_loss, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_rnn(\u001b[43mmodel\u001b[49m,\n\u001b[0;32m      2\u001b[0m           sim_amount\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      3\u001b[0m           training_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m      4\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      5\u001b[0m           num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m      6\u001b[0m           lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0005\u001b[39m,\n\u001b[0;32m      7\u001b[0m           criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[0;32m      8\u001b[0m           optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW,\n\u001b[0;32m      9\u001b[0m           model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbabies_first_RNN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_rnn(model,\n",
    "          sim_amount=1,\n",
    "          training_size=0.8,\n",
    "          batch_size=4,\n",
    "          num_epochs = 200,\n",
    "          lr = 0.0005,\n",
    "          criterion = nn.MSELoss(),\n",
    "          optimizer = optim.AdamW,\n",
    "          model_name = 'babies_first_RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tra.shape:  (76, 64, 64, 2)\n",
      "Y_tra.shape:  (76, 64, 64)\n",
      "X_val.shape:  (20, 64, 64, 2)\n",
      "Y_val.shape:  (20, 64, 64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
